\chapter{Introduction and problem statement}
\label{cha:intro}
With the enormous amount of data we produce nowadays, data mining is becoming more and more prevalent.
Consequently, the goal with modern data mining methods is not only to discover information from crude data, but also to condense that information down to concise descriptions and insights.
One such method is redescription mining~\citep{ramakrishnan_turning_2004}.
In a nutshell, it aims to find different ways to describe the same things.

\chapter{Background Knowledge}
\label{cha:background}
In this chapter we will explore the underlying theory of the thesis.
We will go from more general knowledge to more specific concepts.
Firstly, the data mining idea and framework are introduced.
Then we will dig deeper into frequent itemset mining and redescription mining, which are the two main concepts that the thesis is about.
\section{Data mining}
Why did data mining come up?
This chapter will address that question and then introduce some building blocks of the data mining framework.
\subsection{The problems}
\label{sub:the_problems}
The invention of the computer changed the way we think about storing and managing data.
Unlike books in the library nor merchants in the store, data in computer can grow exponentially and instantaneously like never before.
The need of a systematic way to collect and extract useful information from a big data set started to coin in the late 1980s within company research department  \citep{coenen_datamining_2011}.

One of the first problems that data mining tried to solve is to create decision supports from retail clients transactions and the sales information \citep{coenen_datamining_2011}. 
The aim is to drive the sales up, by giving out suggestions, promotions and special pricing to the targeted customer based on their behaviors.
For example, retailers can use the system to find out which items are frequently bought together, then arrange them close to each other to create a reminding effect, which can increase the sale.
Advance a few decades later, Netflix - a streaming service company - created a system to recommend movies to users based on their favorites and activities \citep{netflix_rs_2016}.
The most difficult part of such system is that the data is often significantly smaller than the search space.
An average person can only watch a limited number of movies, while the total number of movies are vastly bigger.
A long with that, nowadays, with the rising of low-cost communicable devices and sensors, we need to find efficient ways to deal with the data produced by them \citep{data_mining_iot_2014}.
Hence, more sophisticated and clever methods have been invented to deal with the growing of the complexities of the problems.
% TODO improve this

These are just a few examples of some problems that emerged in the modern time of computing and data mining.
As we can imagine, the potential of data mining is unbounded.

\subsection{The main building blocks}
\label{sub:building_blocks}
There are three main phases of data mining: \textit{data collection}, \textit{data preprocessing}, and \textit{analytical processing}.

Data collection usually involving the use of hardware or software to collect raw data.
This could be sensors' data of the environment, or user activities data from the application.
The choice of which data to collect is crucial and can affect greatly of the quality of the result in the later phases.

After the data is collected, it's usually in a form that's difficult to consume directly by the algorithms.
That's why we need the data preprocessing phase to make the data to be easier to be consumed.
This could be structuring the data into known format, e.g. multidimensional format, time series, etc.; or removing bad data.

Analytical processing is the most interesting phase where the useful information or insights start to emerge.
Even though mining processes are different from each other, they often share some similarities and common patterns that we can generalize and apply similar techniques to them.
One of the technique that we will be focusing on in this thesis is the \ac{fim} \citep{borgelt_fim_2012}.

\section{\Acl{fim}}
\Acl{fim} was originally developed for marketing purpose, as introduced in \autoref{sub:the_problems}.
The purpose of the algorithm back then was to try to analyze the sale's transactions data to extract information about which items are frequently bought together.
Nowadays, the applications of \acl{fim} expanded to many more domains, with different variety of tasks.
\subsection{Definitions}
Formally, assume that we have a universe of all possible items $\universeOfItemset$.
For example, this can be all the possible products in a groceries store.
Suppose we have a set of $\mathit{n}$ transaction $\transaction{} = \transactionDef{}$, where $\transaction{i}$ is a composition of items from $\universeOfItemset$, with $i$ is the \ac{tid}.
This in turn, could be possible transactions at a groceries store.
Intuitively, we can see that the size of $\universeOfItemset$ is usually much larger than the size of $\transaction{}$: $|\universeOfItemset| \gg |\transaction{} |$.

A dataset can now be represented in binary representation, where all records have the same length, and each record represents a transaction.
One item in $\universeOfItemset$ will have it own same position in all records.
We can see that the length of each record is basically $|\universeOfItemset|$.
If an item appears in a transaction, it will have value $1$ in the corresponding record, otherwise $0$ (see example in \autoref{tab:market-basket-dataset}).
This representation is analogous to a matrix where the rows are the records and represents the transactions, and the columns are the items.

\begin{table}[tb]
    \centering
    \begin{tabular}{|l|c|c|}
        \hline
        \textbf{\ac{tid}} & \textbf{Transaction}         & \textbf{Binary representation} \\ \hline
        1            & \{Broccoli\}                 & \texttt{100}                   \\ \hline
        2            & \{Carrot\}                   & \texttt{010}                   \\ \hline
        3            & \{Tomato\}                   & \texttt{001}                   \\ \hline
        4            & \{Broccoli, Tomato\}         & \texttt{101}                   \\ \hline
        5            & \{Broccoli, Carrot, Tomato\} & \texttt{111}                   \\ \hline
    \end{tabular}
    \caption{An example of market basket dataset in binary representation}
    \label{tab:market-basket-dataset}
\end{table}

A set of items in $\universeOfItemset$ is an \textit{itemset}. We denote the set of $k$ items \kItemset.
The \textit{support} of an itemset is the frequency where it appears in as a subset of a transaction in the dataset.

\begin{definition}[Support]
    The support of an itemset $\itemset$ is defined as the fraction of the transactions in the database $\transaction{} = \transactionDef{}$ that contain $\itemset$ as a subset \citep{Aggarwal15}.
\end{definition}

The support of itemset $\itemset$ is denoted by $\support{I}$.
The aim of \acl{fim} is to find the itemsets with supports above a predefined \ac{minsup}.


\begin{definition}[\Acl{fim}]
    Given a set of transactions $\transaction{} = \transactionDef{}$, where each transaction $\transaction{i}$ is a subset of items from $\universeOfItemset$, determine all itemsets $\itemset$ that occur as a subset of at least a predefined fraction $\minsup$ of the transactions in $\transaction{}$ \citep{Aggarwal15}.
\end{definition}

\subsection{Apriori}
\subsection{ECLAT}

\section{Redescription mining}


\chapter{Employing ECLAT for Redescription Mining}
\label{cha:employment}

\chapter{Experiments}
\label{cha:experiments}

\chapter{Conclusions}
\label{cha:conclusions}